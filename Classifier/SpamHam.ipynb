{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spamFiles = os.listdir('Spam')\n",
    "hamFiles = os.listdir('Ham')\n",
    "\n",
    "spam = []\n",
    "ham = []\n",
    "\n",
    "for fname in spamFiles:\n",
    "    f = open(\"Spam/\"+fname)\n",
    "    mailStr = \"\"\n",
    "    for line in f:\n",
    "        mailStr = mailStr + line\n",
    "    spam.append(mailStr)\n",
    "\n",
    "for fname in hamFiles:\n",
    "    f = open(\"Ham/\"+fname)\n",
    "    mailStr = \"\"\n",
    "    for line in f:\n",
    "        mailStr = mailStr + line\n",
    "    ham.append(mailStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'spam': spam, 'ham': ham}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickleOut = open('Dataset.pickle', 'wb')\n",
    "pickle.dump(data, pickleOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set([\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\tourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, document in enumerate(spam):\n",
    "    \n",
    "    spam[idx] = spam[idx].replace(\".\", \" \").replace(\"-\", \" \")\\\n",
    "                .replace(\"(\", \" \").replace(\")\", \" \")\\\n",
    "                .replace(\",\", \" \").replace('\\r', \" \")\\\n",
    "                .replace(\":\", \" \").replace(\"\\n\", \" \")\\\n",
    "                .replace(\"/\", \" \").replace(\"!\", \" ! \").replace(\"\\x00\", \"\")\\\n",
    "                .replace(\"\\xff\", \"\").replace(\"\\x10\", \"\")\n",
    "                                           \n",
    "    spam[idx] = spam[idx].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, document in enumerate(ham):\n",
    "    ham[idx] = ham[idx].replace(\".\", \" \").replace(\"-\", \" \")\\\n",
    "                .replace(\"(\", \" \").replace(\")\", \" \")\\\n",
    "                .replace(\",\", \" \").replace('\\r', \" \")\\\n",
    "                .replace(\":\", \" \").replace(\"\\n\", \" \")\\\n",
    "                .replace(\"/\", \" \").replace(\"!\", \" ! \").replace(\"\\x00\", \"\")\\\n",
    "                .replace(\"\\xff\", \"\").replace(\"\\x10\", \"\")\n",
    "                                           \n",
    "    ham[idx] = ham[idx].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(ham):\n",
    "    ham[idx] = [item.lower() for item in ham[idx] if item != \"\" and item.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(spam):\n",
    "    spam[idx] = [item.lower() for item in spam[idx] if item != \"\" and item.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spamtest = spam[int(len(spam)*0.7):]\n",
    "hamtest = ham[int(len(ham)*0.7):]\n",
    "\n",
    "spam = spam[:int(len(spam)*0.7)]\n",
    "ham = ham[:int(len(ham)*0.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We calculate the prior before we split into training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pspam = len(spam)*1.0/(len(spam)+len(ham))\n",
    "Pham = 1-Pspam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.509278874671638, 0.490721125328362)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pspam, Pham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also need the conditional probability of each word given it is spam and non spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate set of all words.\n",
    "wordList = set()\n",
    "for lst in spam:\n",
    "    for word in lst:\n",
    "        wordList.add(word)\n",
    "for lst in ham:\n",
    "    for word in lst:\n",
    "        wordList.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### P_wc = Probability of finding word w given document class c.\n",
    "### P_wc = (count(wi, c)+alpha) / sum(count(w, c)+alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalSpamWords = 0\n",
    "totalHamWords = 0\n",
    "\n",
    "countSpam = {}\n",
    "countHam = {}\n",
    "\n",
    "\n",
    "for lst in spam:\n",
    "    for word in lst:\n",
    "        if word not in countSpam:\n",
    "            countSpam[word] = 0\n",
    "        countSpam[word] += 1\n",
    "        totalSpamWords += 1\n",
    "\n",
    "for lst in ham:\n",
    "    for word in lst:\n",
    "        if word not in countHam:\n",
    "            countHam[word] = 0\n",
    "        countHam[word] += 1\n",
    "        totalHamWords += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def P_wc(word, spam):\n",
    "    if(spam):\n",
    "        occ = 0\n",
    "        if word in countSpam:\n",
    "            occ = countSpam[word]\n",
    "        return np.log((occ + alpha)*1.0 / (totalSpamWords + alpha*len(wordList)))\n",
    "    else:\n",
    "        occ = 0\n",
    "        if word in countHam:\n",
    "            occ = countHam[word]\n",
    "        return np.log((occ + alpha)*1.0 / (totalHamWords + alpha*len(wordList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def guess(email):\n",
    "    ps, ph = np.log(Pspam), np.log(Pham)\n",
    "    \n",
    "    for word in email:\n",
    "        ps += P_wc(word, 1)\n",
    "        \n",
    "    for word in email:\n",
    "        ph += P_wc(word, 0)\n",
    "        \n",
    "\n",
    "    return ps*1.0/(ps+ph) <= 0.498\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965302491103\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for item in hamtest:\n",
    "    if not guess(item):\n",
    "        acc += 1\n",
    "\n",
    "for item in spamtest:\n",
    "    if guess(item):\n",
    "        acc += 1\n",
    "\n",
    "print acc*1.0/(len(spamtest) + len(hamtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00946817082998\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for item in hamtest:\n",
    "    if guess(item):\n",
    "        fp += 1\n",
    "\n",
    "print fp*1.0/len(hamtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RESULTS: So we obtained 96.5% overall accuracy, but fp is 0.9%. This means that for every 100 ham mails, we will have about 1 good mail predicted as spam. We must try to improve it to bring it down as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
